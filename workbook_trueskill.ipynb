{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03470cb-6b7e-4cb8-81c6-464596e25222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from trueskill import TrueSkill, rate_1vs1\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "plt.rcParams[\"lines.linewidth\"] = 3\n",
    "plt.rcParams[\"figure.titlesize\"] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dfee22-3df0-41e7-a4a5-53c136b4329e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1013836-04d6-493d-870d-37ff5f6b1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_preprocessed.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c11b5e-1d68-4bfc-abb6-db0171e65c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dictionary lookup with team id and the day before the team first played. this is the day that we will set the initial rating on\n",
    "\n",
    "teams = pd.melt(df[['winner', 'loser', 'Date']], value_vars=['winner', 'loser'], id_vars='Date', value_name='team', var_name='status')\n",
    "all_teams = teams.team.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca765a5-8397-42ce-b24d-a02d551969a0",
   "metadata": {},
   "source": [
    "## Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140651a-d033-4ec3-9393-23dacf119063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(preds: list, outs: list) -> float:\n",
    "    return np.average((outs - preds) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b0bd65-1f80-4489-833a-0fc04ba923d5",
   "metadata": {},
   "source": [
    "## Trueskill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adabea4-baca-492f-a672-42f0b25ee019",
   "metadata": {},
   "source": [
    "If some player’s rating is β higher than another player’s, the player may have about a 76% (specifically $\\Phi(\\frac{1}{\\sqrt{2}})$ chance to beat the other player. The default value of β is 25/6.\n",
    "\n",
    "$\\Phi$ is the normal CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2873ce1-1e9e-48f8-bef3-b51964ba7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw probability: can be selected individually for each matchup from previous history\n",
    "# we set it here once for the entire history\n",
    "def rate_trueskill(p_draw, mu=25, sigma=8.333, beta=8.333/2, tau=8.333):\n",
    "    ts = TrueSkill(backend='scipy', mu=mu, sigma=sigma, beta=beta, tau=tau)\n",
    "    # set up rating lookup\n",
    "    ratings = dict()\n",
    "    for t in all_teams:\n",
    "        ratings[t] = {'date': [], 'rating': []}\n",
    "    for row in df.itertuples():\n",
    "        # use default rating if team shows up for the first time\n",
    "        try:\n",
    "            old_rating_winner = ratings[row.winner]['rating'][-1]\n",
    "        except IndexError:\n",
    "            old_rating_winner = ts.Rating(mu=mu, sigma=sigma)\n",
    "        try:\n",
    "            old_rating_loser = ratings[row.loser]['rating'][-1]\n",
    "        except IndexError:\n",
    "            old_rating_loser = ts.Rating(mu=mu, sigma=sigma)\n",
    "        \n",
    "        # algorithm magic\n",
    "        winner_new, loser_new = rate_1vs1(old_rating_winner, old_rating_loser, drawn=row.draw)\n",
    "        ratings[row.winner]['date'].append(row.Date)\n",
    "        ratings[row.loser]['date'].append(row.Date)\n",
    "        ratings[row.winner]['rating'].append(winner_new)\n",
    "        ratings[row.loser]['rating'].append(loser_new)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798671b-13fe-40b3-81e8-e3f34bc3c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = rate_trueskill(p_draw=df.draw.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24ffe7-bdd6-4c6c-a45c-ca86739d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting time: let's look at some teams over time!\n",
    "team1 = 'einfrankfurt'\n",
    "team2 = 'bayernmunich'\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(ratings[team1]['date'], [i.mu for i in ratings[team1]['rating']], label=team1)\n",
    "plt.plot(ratings[team2]['date'], [i.mu for i in ratings[team2]['rating']], label=team2)\n",
    "plt.legend()\n",
    "_ = plt.title('trueskill ratings (after match)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a4c72-dc53-46c4-a0cb-fed8b40a07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trueskill with errorbars\n",
    "team = 'bayernmunich'\n",
    "plt.figure()\n",
    "\n",
    "#plt.plot(match_dates[team], elo_30_ratings[team][:-1], label='elo 32')\n",
    "plt.errorbar(ratings[team]['date'], [i.mu for i in ratings[team]['rating']], yerr=[i.sigma for i in ratings[team]['rating']], errorevery=1, ecolor='b', color='r')\n",
    "\n",
    "_ = plt.title(team + ' ratings with confidence intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a45fc2-f703-44db-afd1-f9088358838b",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e6c02-a0a8-4b3b-bf52-00fe97d06f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# win predictions\n",
    "# TrueSkill provides a function (quality()) to calculate a draw probability between arbitrary ratings (because matchmaking is the goal)\n",
    "# But there’s no function for a win probability.\n",
    "\n",
    "def ts_win_probability(r1, r2, p_draw):\n",
    "    delta_mu = r1.mu - r2.mu\n",
    "    sigmas = np.array([r1.sigma, r2.sigma, np.sqrt(2)*8.333/2])\n",
    "    p_1 = norm.cdf(delta_mu / np.linalg.norm(sigmas))\n",
    "    p_2 = 1 - p_1\n",
    "    # correct for draws\n",
    "    p_1 -= 0.5 * p_draw\n",
    "    p_2 -= 0.5 * p_draw\n",
    "    if p_1 < 0:\n",
    "        p_1 = 0\n",
    "        p_2 += np.abs(p_1)\n",
    "    if p_2 < 0:\n",
    "        p2 = 0\n",
    "        p_1 += np.abs(p_2)\n",
    "\n",
    "    return p_1, p_2, p_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5629dc1-2bcb-4c24-b2a1-5495281aad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_on_date(rating_dict, team, date, mu=25, sigma=8.333):\n",
    "    # todo: how do we manage ratings during calibration period?\n",
    "    # since we stored the ratings AFTER the match, we always need to use the one before that day\n",
    "    date_idx = rating_dict[team]['date'].index(date)\n",
    "    if date_idx >= 1:\n",
    "        return rating_dict[team]['rating'][date_idx - 1]\n",
    "    else:\n",
    "        return ts.Rating(mu=mu, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c1ecd-7e1e-4b3b-9171-7cc14a639d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_predictions = []\n",
    "for winner, loser, date in zip(df.winner.values, df.loser.values, df.Date.values):\n",
    "    winner_rating = get_rating_on_date(ratings, winner, date)\n",
    "    loser_rating = get_rating_on_date(ratings, loser, date)\n",
    "    ts_predictions.append(ts_win_probability(winner_rating, loser_rating, p_draw)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a989d4-314e-4b06-9f86-4b97fb1ccbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score(ts_predictions, np.ones(len(ts_predictions))-0.5*df.draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4db18-d7fb-4928-981d-9c41671317cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalift-workshop",
   "language": "python",
   "name": "datalift-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
